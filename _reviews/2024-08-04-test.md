---
layout: review_post
title: "[Paper Review] DyRRen: A Dynamic Retriever-Reranker-Generator Model for
Numerical Reasoning over Tabular and Textual Data"
author: Sohyun
date: 2024-08-04
---


이 논문은 수치적 추론(Numerical Reasoning)을 다루는 작업에 대한 연구이다. LLM의 경우 수치 추론을 진행할 때, 잘못된 답을 내놓는 경우가 종종 있다. 이는 숫자를 일종의 텍스트로 취급함으로써 발생하는 문제인데, 이를 해결하기 위해 쓰이는 방법이 크게 두 가지가 있다. 하나는 외부의 수학과 관련된 라이브러리를 활용하는 것이다. 또다른 하나는 수치와 관련된 데이터가 저장되어 있는 외부 데이터베이스를 활용해서 프롬프트를 증강하는(RAG) 방법이다.

해당 논문에서는 후자인 RAG를 통한 방법인 FinQANet이라는 방법의 한계점을 극복하기 위한 방법인 DyRRen 이라는 프레임워크를 제시한다. 이제 이에 대해 자세히 알아보자.

읽다보니 알게 된 것인데 FinQANet이나 DyRRen 모델은 사용자에게 자연어 형태로 무언가 대답을 만드는 것보다는 수학적 표현식을 생성하는 것(+이를 계산하는 것)이 중점을 둔 것으로 보인다. 어쨋든, 읽어보면서 조금 더 살펴보도록 하자.


## Introduce

기존의 데이터셋, 예를 들어 **DROP(Dua et al. 2019)**[^1]은 주로 간단한 계산이나 비교에 중점을 두었다. 이러한 데이터셋은 주어진 정보를 통해 쉽게 계산할 수 있는 문제를 다루며, 복잡한 논리적 추론을 요구하지 않는 경향이 있었다. 하지만, 금융 보고서와 같은 복잡한 실세계 시나리오에서는 보다 정교한 수치적 추론 능력이 필요하다. 이를 위해 개발된 데이터셋인 FinQA와 TAT-QA는 보다 복잡하고 다양한 정보를 포함한 문제를 해결할 수 있도록 설계되었습니다. 이러한 데이터셋은 기계 학습 모델이 복잡한 수치적 표현을 생성하고 이를 바탕으로 올바른 답을 도출할 수 있도록 돕는다.

예를 들어, FinQA의 한 사례에서는, 연도별 판매 기록을 보여주는 표와 관련 금융 정보를 담고 있는 몇 가지 문장이 제공된다. 여기서 질문에 답하기 위해서는 덧셈, 뺄셈 등의 수학 연산을 결정하고, 그 인자를 표나 문장에서 선택하여 올바른 수학 표현식을 생성한 후 답을 계산해야 한다. 경우에 따라, 수학적 표현식의 한 인자(예: 아래 그림의 #0)는 이전 계산 결과일 수 있다.

![1](https://github.com/user-attachments/assets/5cc21b25-0da1-4dd4-8adb-84e33f1e1af9){: .responsive-img .align-center}


기존의 수치 표현 생성 방법은 Retriever 와 Generator 라는 두 가지 모듈로 나누어졌었다. Retriever 의 경우 가장 관련성이 높은 정보를 찾아서 Generator 에 제공하는 역할을 담당하고, Generator 은 Retriever 가 제공한 정보를 바탕으로 수학적 표현을 만들어낸다. **FinQANet (Chen et al. 2021b)**[^2]는 이 분야에서 잘 알려진 방법 중 하나이고, FinQANet은 다음과 같은 방식으로 작동한다.

Retriever Phase: 표를 문장으로 변환하고, BERT 기반의 이진 분류기를 사용하여 관련 문장을 선택한다.
Generator Phase: Encoder-Decoder 모델을 사용하여 수학적 표현을 생성한다. 여기서 인코더는 BERT나 RoBERT를 사용할 수 있으며, LSTM의 히든 레이어 출력이 표현식 토큰을 예측하는 데 사용된다.

하지만 FinQANet에는 몇 가지 한계가 있다.

1. **긴 문장 연결의 문제**: FinQANet의 생성기는 선택된 문장(검색된 문서에서 가져온 것)을 길게 연결하여 인코더에 입력한다. 이는 특정 숫자를 정확히 찾기 어려운 상황을 만든다. 예를 들어, “7%“라는 숫자를 생성해야 할 때, “7%“가 포함된 특정 문장에만 어텐션해야 하지만, FinQANet은 이를 잘 처리하지 못한다. 

2. **Retriever의 단순성**: FinQANet의 리트리버는 단순한 이진 분류기를 사용하여 각 문장이 질문과 관련이 있는지 없는지를 판단한다. 즉, 단순히 “관련 있다” 또는 “관련 없다”로만 분류하기 때문에, 문장 간의 미세한 차이나 복잡한 상호작용을 이해하기 어렵다. 예를 들어, 질문에서 특정 연도(“2015”, “2016”)나 항목(“제3자 판매”)에 집중해야 하지만, 이는 어려운 일이다. 또한 질문에서 요구하는 세부적인 정보를 정확히 찾아내기 위해서는 단순한 관련성 이상의 **정교한 추론**이 필요하다. 예를 들어, 질문이 “2015년과 2016년의 제3자 판매 차이는?“이라고 한다면, 리트리버는 단순히 ‘판매’와 관련된 모든 문장을 선택하는 것보다 더 깊이 있는 분석을 통해 정확한 정보를 찾아야 한다.  

이 논문에서는 위의 문제를 해결하기 위해 **DyRRen**이라는 새로운 프레임워크를 제안한다. DyRRen은 생성의 각 단계에서 문장에 대한 주의를 동적으로 조정하는 **동적 재순위 메커니즘(Dynamic ReRanker Mechanism)**을 사용한다.

  
**DyRRen의 주요 구성 요소**

•  **Generator (생성기)**: 이 모듈은 LSTM과 주의(attention) 메커니즘을 사용하여, 입력된 토큰을 평가하고 다음에 생성할 가능성이 높은 토큰을 찾아낸다. 생성기의 정확성을 높이기 위해 **재순위기(reranker)**를 사용하여 검색된 문장들 중 관련 문장을 동적으로 선택한다.

•  **Reranker (재순위기)**: 생성의 각 단계에서 검색된 문장을 평가하고 순위를 매겨서 목표 숫자를 포함하는 문장을 찾는다. 이를 위해 생성기의 출력, 이전에 생성된 표현식, 그리고 검색된 문장 간의 관계를 활용하여 각 단계에서 문장을 동적으로 재순위한다.

•  **Retriever (리트리버)**: 기존의 간단한 BERT 이진 분류기 대신 **밀도 검색(dense retrieval)**을 사용한다. 검색 성능을 향상시키기 위해 질문과 문장 쌍 간의 정교한 상호작용을 구현하고, 토큰 수준의 늦은 상호작용을 활용한다. 이 과정에서 긍정적 및 부정적 문장이 다수 포함된 검색 공간을 다루기 위해 손실 함수를 조정한다.

  
![2](https://github.com/user-attachments/assets/d5c3eebb-c34f-49f9-a0ac-a73faa11d862){: .responsive-img .align-center}

여기선 간단히 다루고 뒤쪽에서 각 접근법에 대해 자세히 다룰 예정이다.


이 논문에서 제안하는 주요 기여는 다음과 같다:

•  **새로운 프레임워크**: 숫자 추론 문제를 해결하기 위한 새로운 **Retriever-Reranker-Generator** 프레임워크를 제안한다. 특히, 재순위기를 통해 다른 생성 단계에서 목표 정보를 동적으로 찾아낼 수 있도록 한다.

•  **정교한 Retriever 설계**: 토큰 수준과 질문-문장 쌍별 상호작용을 강화하여 Retriever를 설계하였다.

  
DyRRen의 코드는 GitHub에 공개되어있다. [DyRRen GitHub](https://github.com/nju-websoft/DyRRen).


이제 이 DyRRen 모델의 접근을 보다 자세히 살펴보도록 하자.

DyRRen 모델의 목표는 주어진 질문 $Q$, 표 $T$, 비구조화된 문장 집합 $D$로부터 산술 표현식 $G$를 생성하는 것이다. 이 표현식은 특정 도메인 언어(DSL)로 정의된 이항 연산자(op)와 다양한 인자(args)를 포함한다. 인자는 상수, 이전 연산 결과를 나타내는 메모리 토큰, 또는 질문, 표, 문장에 나타나는 숫자나 범위일 수 있다. 일단 모델을 쪼갠 후, 각 부분에 대해 살펴보자.


### Retriever

![5](https://github.com/user-attachments/assets/c9c67523-c090-42dc-abb3-b7d09cf50715){: .responsive-img .align-center}

Retriever 의 목적은 표 $T$와 문장 $D$에서 질문 $Q$에 대한 답을 지원하는 사실을 검색하는 것이다.

이를 위해 다음과 같은 과정을 거친다.

1. 테이블 데이터 처리
2. BERT 인코딩
3. 유사성 점수 계산
4. 손실 함수

먼저 테이블에 있는 각 행의 데이터를 특정 템플릿을 사용해 문장으로 변환한다.

**“the "column name" of "row name" is "cell value" ;”**

이런 형태로 변환하는데, 위의 표를 토대로 작성하면 “2016년 제3자 판매는 $1802; 2015년 제3자 판매는 $1882; …“와 같이 변환된다. 이렇게 변환된 문장과 검색된 문장을 합쳐 $D'$ 집합을 만든다. $D' = {D_1,D_2,··· ,D_n}∪{D_{n+1},D_{n+2},··· ,D_{n+r}}$ 여기서 합집합 앞의 $D_n$의 경우 검색된 문장을 의미하고, 뒤의 $D_{n+1}$ 부분은 테이블을 문장형태로 변환한 것을 의미한다.

이렇게 만들어진 집합 $D'$와 질문 $Q$를 BERT 를 사용하여 인코딩한다, 이를 통해 $H^Q$ 와 $H^D$ 라는 표현을 생성한다. 인코딩을 할 때, BERT의 기능을 향상 시키기 위해, 질문과 문장 파트에 각각 특별한 토큰 $[Q]$와 $[D]$를 추가했다. (이로 인해, 모델은 학습을 하면서 질문과 문장 집합을 명확하게 구분하게 된다고 한다.) 또한 질문 토큰을 $[mask]$ 토큰으로 패딩하여 질문의 길이를 고정시킴으로써 BERT가 질문의 의미를 최적화하도록 하였다. 그리고 질문과 문장 $Q, D$를 하나의 시퀀스로 연결하여 상호작용을 강화하였다.

이러한 시퀀스를 인코딩 한 후, 유사성(관련성) 검사를 ColBERT 의 Late Interaction 메커니즘을 활용하여 진행한다. 

질문 $Q$와 문장 $D'$ 의 각 토큰은 결과적으로 $[H_Q^1, H_Q^2, \ldots, H_Q^m]$와, $[H_D^1, H_D^2, \ldots, H_D^n]$ 임베딩 벡터를 가지게 된다.

각 토큰에 대해서 내적 계산을 통해 두 벡터 간의 유사성을 측정하고, 각 질문 토큰 $H_Q^i​$에 대해 가장 유사한 문장 토큰을 선택한다.
    
 $$   \text{sim}(h_Q^i, h_D^j) = \frac{h_Q^i \cdot h_D^j}{\|h_Q^i\| \|h_D^j\|}$$
 
 이를 위해 각 질문 토큰 $h_Q^i$에 대해 문장 토큰 $h_D^j$의 유사성 중 최대 값을 찾는다. 

$$\text{MaxSim}(h_Q^i) = \max_j (\text{sim}(h_Q^i, h_D^j))$$

그 후 각 질문 토큰에 대해 최대 유사성 값을 합산하여 전체 문장 $D$에 대한 관련성 점수를 계산한다.

$$\text{Score}(Q, D) = \sum_i \text{MaxSim}(h_Q^i)$$

이 식들을 하나의 식으로 표현하면 아래와 같다.

$$
\text{sim}(H_Q, H_D) = \sum_{H_Q^i \in H_Q} \max_{H_D^j \in H_D} \frac{H_Q^i \cdot H_D^j}{\|H_Q^i\| \|H_D^j\|}
$$

$$
L(Q, D^+, D^−) = \sum_{i \in D^+} \sum_{j \in D^-} \log\left(1 + \frac{\exp\left(\text{sim}(H_Q, H_{D_j}^-)\right)}{\exp\left(\text{sim}(H_Q, H_{D_i}^+)\right)}\right)
$$







[^1]: [DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs](https://aclanthology.org/N19-1246.pdf)

[^2]:A Numerical Reasoning Question Answering System with Fine-grained Retriever and the Ensemble of Multiple Generators for FINQA
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTc0NTY0NzIxMSw1NzI4NTg4NzQsNjIyMz
M2MzkwLC0xNDUyODU2NDg4LDUxMjY5MTAzNCwxODgzNTU2Njc1
LC0xMzgzODA4OTQ1LDU4MTU0MjksNTA0ODI2NDAyLC04OTQwMD
Y5OCwtODkyNTY2MjU1LC0xMjM0OTM2NjgzLC03Nzk2NTUwOCw4
MDgzNjIzMTAsNzAwMDkxMzIxLC0xODIzMjUwNCwtMTQxOTI4ND
Y4NiwtMTk1MDg2MTk0MSwxMzU4OTI3Mzc2LC05NDg4ODI3ODJd
fQ==
-->