---
layout: review_post
title: "[Paper Review] DyRRen: A Dynamic Retriever-Reranker-Generator Model for
Numerical Reasoning over Tabular and Textual Data"
author: Sohyun
date: 2024-08-04
---


이 논문은 수치적 추론(Numerical Reasoning)을 다루는 작업에 대한 연구이다. LLM의 경우 수치 추론을 진행할 때, 잘못된 답을 내놓는 경우가 종종 있다. 이는 숫자를 일종의 텍스트로 취급함으로써 발생하는 문제인데, 이를 해결하기 위해 쓰이는 방법이 크게 두 가지가 있다. 하나는 외부의 수학과 관련된 라이브러리를 활용하는 것이다. 또다른 하나는 수치와 관련된 데이터가 저장되어 있는 외부 데이터베이스를 활용해서 프롬프트를 증강하는(RAG) 방법이다.

해당 논문에서는 후자인 RAG를 통한 방법인 FinQANet이라는 방법의 한계점을 극복하기 위한 방법인 DyRRen 이라는 프레임워크를 제시한다. 이제 이에 대해 자세히 알아보자.

읽다보니 알게 된 것인데 FinQANet이나 DyRRen 모델은 사용자에게 자연어 형태로 무언가 대답을 만드는 것보다는 수학적 표현식을 생성하는 것(+이를 계산하는 것)이 중점을 둔 것으로 보인다. 어쨋든, 읽어보면서 조금 더 살펴보도록 하자.


## Introduce

기존의 데이터셋, 예를 들어 **DROP(Dua et al. 2019)**[^1]은 주로 간단한 계산이나 비교에 중점을 두었다. 이러한 데이터셋은 주어진 정보를 통해 쉽게 계산할 수 있는 문제를 다루며, 복잡한 논리적 추론을 요구하지 않는 경향이 있었다. 하지만, 금융 보고서와 같은 복잡한 실세계 시나리오에서는 보다 정교한 수치적 추론 능력이 필요하다. 이를 위해 개발된 데이터셋인 FinQA와 TAT-QA는 보다 복잡하고 다양한 정보를 포함한 문제를 해결할 수 있도록 설계되었습니다. 이러한 데이터셋은 기계 학습 모델이 복잡한 수치적 표현을 생성하고 이를 바탕으로 올바른 답을 도출할 수 있도록 돕는다.

예를 들어, FinQA의 한 사례에서는, 연도별 판매 기록을 보여주는 표와 관련 금융 정보를 담고 있는 몇 가지 문장이 제공된다. 여기서 질문에 답하기 위해서는 덧셈, 뺄셈 등의 수학 연산을 결정하고, 그 인자를 표나 문장에서 선택하여 올바른 수학 표현식을 생성한 후 답을 계산해야 한다. 경우에 따라, 수학적 표현식의 한 인자(예: 아래 그림의 #0)는 이전 계산 결과일 수 있다.

![1](https://github.com/user-attachments/assets/5cc21b25-0da1-4dd4-8adb-84e33f1e1af9){: .responsive-img .align-center}


기존의 수치 표현 생성 방법은 Retriever 와 Generator 라는 두 가지 모듈로 나누어졌었다. Retriever 의 경우 가장 관련성이 높은 정보를 찾아서 Generator 에 제공하는 역할을 담당하고, Generator 은 Retriever 가 제공한 정보를 바탕으로 수학적 표현을 만들어낸다. **FinQANet (Chen et al. 2021b)**[^2]는 이 분야에서 잘 알려진 방법 중 하나이고, FinQANet은 다음과 같은 방식으로 작동한다.

Retriever Phase: 표를 문장으로 변환하고, BERT 기반의 이진 분류기를 사용하여 관련 문장을 선택한다.
Generator Phase: Encoder-Decoder 모델을 사용하여 수학적 표현을 생성한다. 여기서 인코더는 BERT나 RoBERT를 사용할 수 있으며, LSTM의 히든 레이어 출력이 표현식 토큰을 예측하는 데 사용된다.

하지만 FinQANet에는 몇 가지 한계가 있다.

1. **긴 문장 연결의 문제**: FinQANet의 생성기는 선택된 문장(검색된 문서에서 가져온 것)을 길게 연결하여 인코더에 입력한다. 이는 특정 숫자를 정확히 찾기 어려운 상황을 만든다. 예를 들어, “7%“라는 숫자를 생성해야 할 때, “7%“가 포함된 특정 문장에만 어텐션해야 하지만, FinQANet은 이를 잘 처리하지 못한다. 

2. **Retriever의 단순성**: FinQANet의 리트리버는 단순한 이진 분류기를 사용하여 각 문장이 질문과 관련이 있는지 없는지를 판단한다. 즉, 단순히 “관련 있다” 또는 “관련 없다”로만 분류하기 때문에, 문장 간의 미세한 차이나 복잡한 상호작용을 이해하기 어렵다. 예를 들어, 질문에서 특정 연도(“2015”, “2016”)나 항목(“제3자 판매”)에 집중해야 하지만, 이는 어려운 일이다. 또한 질문에서 요구하는 세부적인 정보를 정확히 찾아내기 위해서는 단순한 관련성 이상의 **정교한 추론**이 필요하다. 예를 들어, 질문이 “2015년과 2016년의 제3자 판매 차이는?“이라고 한다면, 리트리버는 단순히 ‘판매’와 관련된 모든 문장을 선택하는 것보다 더 깊이 있는 분석을 통해 정확한 정보를 찾아야 한다.  

이 논문에서는 위의 문제를 해결하기 위해 **DyRRen**이라는 새로운 프레임워크를 제안한다. DyRRen은 생성의 각 단계에서 문장에 대한 주의를 동적으로 조정하는 **동적 재순위 메커니즘(Dynamic ReRanker Mechanism)**을 사용한다.

  
**DyRRen의 주요 구성 요소**

•  **Generator (생성기)**: 이 모듈은 LSTM과 주의(attention) 메커니즘을 사용하여, 입력된 토큰을 평가하고 다음에 생성할 가능성이 높은 토큰을 찾아낸다. 생성기의 정확성을 높이기 위해 **재순위기(reranker)**를 사용하여 검색된 문장들 중 관련 문장을 동적으로 선택한다.

•  **Reranker (재순위기)**: 생성의 각 단계에서 검색된 문장을 평가하고 순위를 매겨서 목표 숫자를 포함하는 문장을 찾는다. 이를 위해 생성기의 출력, 이전에 생성된 표현식, 그리고 검색된 문장 간의 관계를 활용하여 각 단계에서 문장을 동적으로 재순위한다.

•  **Retriever (리트리버)**: 기존의 간단한 BERT 이진 분류기 대신 **밀도 검색(dense retrieval)**을 사용한다. 검색 성능을 향상시키기 위해 질문과 문장 쌍 간의 정교한 상호작용을 구현하고, 토큰 수준의 늦은 상호작용을 활용한다. 이 과정에서 긍정적 및 부정적 문장이 다수 포함된 검색 공간을 다루기 위해 손실 함수를 조정한다.

  
![2](https://github.com/user-attachments/assets/d5c3eebb-c34f-49f9-a0ac-a73faa11d862){: .responsive-img .align-center}


각 구성 요소는 개별적으로 학습되고 최적화되며, 최종 모델에서는 이들이 통합되어 작동한다.
여기선 간단히 다루고 뒤쪽에서 각 접근법에 대해 자세히 다룰 예정이다.


이 논문에서 제안하는 주요 기여는 다음과 같다:

•  **새로운 프레임워크**: 숫자 추론 문제를 해결하기 위한 새로운 **Retriever-Reranker-Generator** 프레임워크를 제안한다. 특히, 재순위기를 통해 다른 생성 단계에서 목표 정보를 동적으로 찾아낼 수 있도록 한다.

•  **정교한 Retriever 설계**: 토큰 수준과 질문-문장 쌍별 상호작용을 강화하여 Retriever를 설계하였다.

  
DyRRen의 코드는 GitHub에 공개되어있다. [DyRRen GitHub](https://github.com/nju-websoft/DyRRen).


이제 이 DyRRen 모델의 접근을 보다 자세히 살펴보도록 하자.

DyRRen 모델의 목표는 주어진 질문 $Q$, 표 $T$, 비구조화된 문장 집합 $D$로부터 산술 표현식 $G$를 생성하는 것이다. 이 표현식은 특정 도메인 언어(DSL)로 정의된 이항 연산자(op)와 다양한 인자(args)를 포함한다. 인자는 상수, 이전 연산 결과를 나타내는 메모리 토큰, 또는 질문, 표, 문장에 나타나는 숫자나 범위일 수 있다. 일단 모델을 쪼갠 후, 각 부분에 대해 살펴보자.


### Retriever

![5](https://github.com/user-attachments/assets/c9c67523-c090-42dc-abb3-b7d09cf50715){: .responsive-img .align-center}

Retriever 의 목적은 표 $T$와 문장 $D$에서 질문 $Q$에 대한 답을 지원하는 사실을 검색하는 것이다.

이를 위해 다음과 같은 과정을 거친다.

1. 테이블 데이터 처리
2. BERT 인코딩
3. 유사성 점수 계산
4. 손실 함수

먼저 테이블에 있는 각 행의 데이터를 특정 템플릿을 사용해 문장으로 변환한다.

**“the "column name" of "row name" is "cell value" ;”**

이런 형태로 변환하는데, 위의 표를 토대로 작성하면 “2016년 제3자 판매는 $1802; 2015년 제3자 판매는 $1882; …“와 같이 변환된다. 이렇게 변환된 문장과 검색된 문장을 합쳐 $D'$ 집합을 만든다. $D' = {D_1,D_2,··· ,D_n}∪{D_{n+1},D_{n+2},··· ,D_{n+r}}$ 여기서 합집합 앞의 $D_n$의 경우 검색된 문장을 의미하고, 뒤의 $D_{n+1}$ 부분은 테이블을 문장형태로 변환한 것을 의미한다.

이렇게 만들어진 집합 $D'$와 질문 $Q$를 BERT 를 사용하여 인코딩한다, 이를 통해 $H^Q$ 와 $H^D$ 라는 표현을 생성한다. 인코딩을 할 때, BERT의 기능을 향상 시키기 위해, 질문과 문장 파트에 각각 특별한 토큰 $[Q]$와 $[D]$를 추가했다. (이로 인해, 모델은 학습을 하면서 질문과 문장 집합을 명확하게 구분하게 된다고 한다.) 또한 질문 토큰을 $[mask]$ 토큰으로 패딩하여 질문의 길이를 고정시킴으로써 BERT가 질문의 의미를 최적화하도록 하였다. 그리고 질문과 문장 $Q, D$를 하나의 시퀀스로 연결하여 상호작용을 강화하였다.

이러한 시퀀스를 인코딩 한 후, 유사성(관련성) 검사를 ColBERT 의 Late Interaction 메커니즘을 활용하여 진행한다. 

질문 $Q$와 문장 $D'$ 의 각 토큰은 결과적으로 $[H_Q^1, H_Q^2, \ldots, H_Q^m]$와, $[H_D^1, H_D^2, \ldots, H_D^n]$ 임베딩 벡터를 가지게 된다.

각 토큰에 대해서 내적 계산을 통해 두 벡터 간의 유사성을 측정하고, 각 질문 토큰 $H_Q^i​$에 대해 가장 유사한 문장 토큰을 선택한다.
    
 $$   \text{sim}(h_Q^i, h_D^j) = \frac{h_Q^i \cdot h_D^j}{\|h_Q^i\| \|h_D^j\|}$$
 
 이를 위해 각 질문 토큰 $h_Q^i$에 대해 문장 토큰 $h_D^j$의 유사성 중 최대 값을 찾는다. 

$$\text{MaxSim}(h_Q^i) = \max_j (\text{sim}(h_Q^i, h_D^j))$$

그 후 각 질문 토큰에 대해 최대 유사성 값을 합산하여 전체 문장 $D$에 대한 관련성 점수를 계산한다.

$$\text{Score}(Q, D) = \sum_i \text{MaxSim}(h_Q^i)$$

이 식들을 하나의 식으로 표현하면 아래와 같다.

$$
\text{sim}(H_Q, H_D) = \sum_{H_Q^i \in H_Q} \max_{H_D^j \in H_D} \frac{H_Q^i \cdot H_D^j}{\|H_Q^i\| \|H_D^j\|}
$$

그 후 RankNet 쌍별 손실 함수(RankNet pairwise loss)를 활용하여 문장을 긍정적(positive)인 문장과 부정적(negative)인 문장으로 구분하고, 긍정적인 문장이 부정적인 문장보다 더 높은 점수를 가지도록 학습시킨다. 
RankNet 쌍별 손실 함수는 아래와 같다.

$$
L(Q, D^+, D^−) = \sum_{D_i \in D^+} \sum_{D_j \in D^-} \log\left(1 + \frac{\exp\left(\text{sim}(H_Q, H_{D_j}^-)\right)}{\exp\left(\text{sim}(H_Q, H_{D_i}^+)\right)}\right)
$$



### Generator

Generator 은 기본적으로 FinQANet의 생성기를 확장하여 동적 재정렬기를 통합함으로써 산술 표현식의 정확성을 높이는 방향으로 설계되었다. Generator의 목표는 질문 $Q$와 검색된 문장 집합 $D_R = \{ D_{R_1}, \cdots, D_{R_k} \}$을 기반으로 표현식을 생성하는 것이다.

#### Encoder

![6](https://github.com/user-attachments/assets/a9b48dee-677e-4410-9e6f-04ea7bcccbc9){: .responsive-img .align-center}



생성기의 인코더는 검색기와 유사하게 작동한다. 먼저 질문 $Q$를 인코딩한다.  질문 $Q$는 BERT를 사용하여 인코딩되고, 다음과 같은 표현을 얻는다:$$H_Q = [h^Q_1; h^Q_2; \cdots; h^Q_{|Q|+2}] = \text{BERT}([\text{CLS}], u^Q_1, u^Q_2, \cdots, u^Q_{|Q|}, [\text{SEP}])$$
- 여기서 $u^Q_i$​는 질문의 토큰들이다.

그리고 각 검색된 문장 $D_{R_i}$​​는 질문 $Q$와 연결되어 인코딩되며, 이를 통해 질문과 완전히 상호작용 할 수 있도록 한다: 

$$
H_{D_{R_i}} = [h^{D_{R_i}}_1; h^{D_{R_i}}_2; \cdots; h^{D_{R_i}}_{|D_{R_i}| + |Q| + 3}] = \text{BERT}([\text{CLS}], u^{D_{R_i}}_1, \cdots, u^{D_{R_i}}_{|D_{R_i}|}, [\text{SEP}], u^Q_1, \cdots, u^Q_{|Q|}, [\text{SEP}])
$$

이 표현은 각 문장이 질문 토큰과 상호작용하여 더 나은 맥락적 이해를 가능하게 한다.

이렇게 생성된 질문과 검색된 모든 문장의 표현 $H_Q$ 와 $H_{D_{R_i}}$을 연결한다. 

$$H = H_Q \parallel H_{D_{R_1}} \parallel \cdots \parallel H_{D_{R_k}}$$

DyRRen 모델에서는 도메인 특화 언어(DSL: Domain Specific Language)를 사용한다. DSL의 구성 요소로는  이항 연산자, 테이블 행 헤더를 사용하는 연산자와 같은 것들이 있고, 상수 토큰,  그리고 메모리 토큰 같은 것들이 있다. 자세한 내용은 아래와 같다.


-   **이항 연산자 (Binary Operators)**:
    
    -   **예시**: `ADD`, `DIVIDE` 등
    -   **기능**: 숫자 인수를 사용하여 연산을 수행한다. 예를 들어, `ADD`는 두 숫자를 더하고, `DIVIDE`는 하나의 숫자를 다른 숫자로 나눈다.
    
-   **테이블 행 헤더를 사용하는 연산자 (Operators with Table Row Headers)**:
    
    -   **예시**: `TABLE SUM`, `TABLE MAX` 등
    -   **기능**: 특정 테이블 행에서 연산을 수행한다. 예를 들어, `TABLE SUM`은 행의 모든 값을 합치고, `TABLE MAX`는 행의 값 중 최대값을 찾는다.
    - 
-   **상수 토큰 (Constant Tokens)**:
    
    -   **예시**: `CONST 1`, `CONST 100`, `CONST 1000` 등
    -   **기능**: 고정된 숫자 값을 표현하는데 사용된다.
-   **메모리 토큰 (Memory Tokens)**:
    
    -   **예시**: `#0`, `#1` 등
    -   **기능**: 이전 연산의 결과를 저장하고 참조하는 데 사용된다. 예를 들어, `#0`은 첫 번째 연산의 결과를 나타낸다.

이러한 DSL 토큰도 초기화 및 학습이 된다. DSL에 포함된 모든 토큰의 집합 토큰의 집합 $U_{DSL}$ 은 아래와 같이 정의된다.

$$U_{DSL} = \{u^{DSL}_1, u^{DSL}_2, \ldots, u^{DSL}_m\}$$

모든 DSL 토큰에 대해 벡터 표현을 초기화 한다. 학습 시에는 무작위로 초기화 되며, 이를  $H_{DSL}$로 표현한다.

$$H_{DSL} = [h^{DSL}_1; h^{DSL}_2; \cdots; h^{DSL}_m]$$


이와 관련된 내용이 논문 중간에 갑자기 나오는데 이후에 이야기하는 것이 결과를 생성하는 디코더라 그런 것 같다. 어쨋든, 이제 디코더에 대해 살며보자.


#### Decoder

![7](https://github.com/user-attachments/assets/0b60179a-b1e9-4da1-9d7d-8b1d584f5dc6){: .responsive-img .align-center}


디코더는 LSTM과 어텐션 메커니즘을 단계적으로 조합하여 입력 데이터에서 출력 토큰을 생성한다.

디코더 이야기를 하기 전, 어텐션 메커니즘을 먼저 설명한다. 어텐션 메커니즘은 특정 시점에 가장 관련 있는 정보를 선택할 수 있도록 돕는다. 
	
$$\text{Attention}(Q, K, V) = \text{Softmax}(W_Q QK^T)V$$

위와 같은 수식으로 표현되며, 여기서  $W_Q$ 는 학습 가능한 매개변수 행렬입니다.  $Q ,  K ,  V$는 각각 Query, Key, Value를 나타낸다.

먼저 디코더는 LSTM 네트워크를 사용하며, 이전 단계의 출력 토큰을 기반으로 현재 단계의 출력을 생성한다.
	
$$\hat{y}t = \text{LSTM}(y{t-1})$$
	
이 식은 LSTM이 이전 단계  $y_{t-1}$ 의 출력을 입력으로 받아 현재 출력 $\hat{y}t$를 생성하는 과정을 나타낸다. 초기 입력  $y_0$ 는 훈련 시 무작위로 초기화되며, 이후 단계에서는 이전 단계에서 생성된 토큰  $y{t-1}$ 을 입력으로 받는다.

> 위 식, 그리고 후술할 내용에서 $t$  단계에서의 변수들은 명시적으로 적지 않고  $t$ 로 간주한다.

LSTM은 현재 단계  $t$ 에서 이전 단계의 출력  $y_{t-1}$ 를 사용하여 현재 출력  $\hat{y}_t$ 를 생성한다.

디코더는 현재 단계에서 두 가지의 어텐션 메커니즘을 사용한다. 하나는 이전에 생성된 토큰 시퀀스  $Y_t = [y_1; y_2; \cdots; y_{t-1}]$ 에 대한 것이고, 다른 하나는 DSL 및 질문의 표현  $H_{DSL} \| H$, 즉 전체 입력 데이터에 대해 집중할 부분을 결정한다. 생성된 $\hat{y}_t$는 어텐션 메커니즘의 쿼리로 사용된다. 이는 현재 단계에서 가장 중요하게 고려해야 할 정보를 찾기 위한 출발점이 된다.

첫 번째 어텐션 메커니즘(디코더 이력에 대한 어텐션)은 $\hat{y}_t$와 이전에 생성된 모든 토큰 시퀀스 $Y_t$ 사이의 관련성을 계산한다. 즉, 디코더가 과거에 생성한 내용과의 맥락을 이해하고, 이를 고려하여 연속성이나 문법적 흐름을 유지하는 데 중요하다. 이를 기반으로 다음에 생성할 토큰에 영향을 준다.
	
$$a_Y = \text{Attention}(Q = \hat{y}t, K = Y_t, V = Y_t)$$

이 과정을 통해 현재 단계에서 이전 단계의 정보 중 어떤 부분에 집중할지를 결정한다.

두 번째 어텐션은 현재 토큰이 전체 입력 데이터, 즉 DSL과 질문 표현  $H_{DSL} \| H$(인코더로 부터의 입력 + 디코더의 입력) 에 얼마나 집중해야 하는지를 결정한다. 즉, 모델이 외부 입력에서 필요한 정보를 강조하여, 정답을 생성하는 데 직접적으로 필요한 정보를 제공하는 데 중점을 둔다.

$$a{\text{seq}} = \text{Attention}(Q = \hat{y}t, K = H{DSL} \| H, V = H_{DSL} \| H)$$

> 여기서  $Q$ 는 현재 단계의 출력 $\hat{y}_t$,  $K$ 와  $V$ 는 DSL과 질문의 결합 표현이다.

여기서도 현재 출력 $\hat{y}_t$를 쿼리로 사용하여, 입력 데이터의 각 부분이 얼마나 중요한지를 평가한다. 이는 디코더가 질문과 관련된 입력 데이터의 맥락을 이해하고, 그중에서 필요한 정보를 선택하는 데 도움을 준다.

이렇게 생성된 두 어텐션 결과  $a_Y$ 와  $a_{\text{seq}}$ 를 결합하여 현재 단계의 컨텍스트 표현  $h_c$ 를 생성한다. 이 단계에서는 Layernorm을 사용하여 표현을 정규화하고, LSTM의 출력과 어텐션 결과를 결합한다.

$$h_c = \text{Layernorm}(W_c(a_Y \| a_{\text{seq}} \| \hat{y}_t))$$

> 여기서 $W_c$ 는 학습 가능한 매개변수 행렬이며,  $\|$ 는 벡터의 연결을 나타낸다.

앞서 구한 $H_{DSL}$과 질문 및 문장과 관련된 벡터인 $H$ 벡터를 합친 모든 가능한 토큰의 벡터 표현 $H_{DSL} \| H$ 을 생성하고, 여기에 어텐션 가중치인  $a_{\text{seq}}$를 벡터의 각 요소에 곱하여 중요도를 조정한다. 그리고 아래의 식에서 보이는 것과 같이 $(H_{DSL} \| H)$와 $((H_{DSL} \| H) \circ a_{\text{seq}})$를 다시 결합하여 최종 점수를 계산하기 위한 입력으로 사용한다. $((H_{DSL} \| H) \circ a_{\text{seq}})$를 다시 결합하는 이유는 각 토큰 고유의 표현과 가중치가 적용되어 중요도를 반영한 강화된 표현을 결합함으로써 각 토큰이 기본적으로 수행할 수 있는 역할과 현재 맥락에서의 중요성을 동시에 고려할 수 있게 된다고 한다. (왜 두 개를 결합하는지 잘 모르겠으나, 이런 복합적 접근이 경험적으로 더 정확한 결과를 생성한다고 한다.) 이러한 과정을 아래와 같은 식으로 표현하였다.

$$H_S = W_S((H_{DSL} \| H) \| ((H_{DSL} \| H) \circ a_{\text{seq}}))$$

위 식에서 $H_S$는 모든 가능한 출력 토큰의 벡터 표현에 가중치 $W_S$가 적용된 결과로, 각 토큰의 점수를 포함한다(이는 각 토큰이 선택될 가능성을 나타낸다). 이 점수와 이전에 구한 컨텍스트 벡터 $h_c$(현재 단계에서 입력 데이터와 문제의 맥락을 반영)를 내적을 하여 주어진 컨텍스트에서 각 토큰이 얼마나 적합한가를 평가한다. 즉, 컨텍스트 기반 점수를 구한다.

$$s_{\text{ctx}} = H_S h_c$$


마지막으로 Reranker(재정렬기) 모듈에서 계산된 점수 $s_r$ 과 컨텍스트 기반 점수 $s_{ctx}$ 를 곱하여 최종 점수를 계산한다. 

$$s = s_{\text{ctx}} \circ s_r$$

훈련 중에는 크로스 엔트로피 손실 함수를 최적화한다:

$$L = -\log \frac{\exp(s_{\text{gold}})}{\sum_{\text{tok} \in U_{DSL} \cup U_{\text{num}}} \exp(s_{\text{tok}})}$$

여기서  $s_{\text{gold}}$ 는 실제 정답 토큰의 최종 점수이고,  $s_{\text{tok}}$는 위의 앞선 식에서 계산된 각 토큰의 최종 점수 $s$ 이다. $U_{\text{num}}$는 모든 수치형 토큰의 집합이고, 모델이 수치 연산을 포함한 문제를 해결할 때 고려해야 할 모든 수치형 토큰을 포함한다.

> $s_{\text{gold}}$의 경우 계산된 최종 점수 벡터  s 에서, 실제 정답 토큰에 해당하는 인덱스의 값을  $s_{\text{gold} }$ 로 선택한다.

최종적으로, 예측된 토큰은 다음 수식을 통해 선택됩니다:

$$y_t = H_S \arg \max s$$

 $\arg \max s$는 $s$ 점수 벡터에서 가장 높은 점수를 갖는 토큰의 인덱스를 찾는다. 해당 인덱스를 이용하여 $H_S$에서 가장 높은 점수를 받은 토큰의 표현을 선택한다. 그 토큰이 바로 $y_t$, 즉 현재 단계에서 예측 및 선택되고 최종 출력으로 결정된다. 그리고 이 토큰을 다음 단계로 넘겨 $y_{t+1}$을 계산하기 위해 사용된다.
 
훈련 중에는 교사 강제(teacher forcing) 기법을 사용하여 실제 정답 토큰의 표현을  $y_t$ 로 사용한다. 이는 모델이 빠르고 안정적으로 학습할 수 있도록 돕는다고 한다.

> 교사 강제는 훈련 과정에서 모델이 예측하는 출력 대신 실제 정답 시퀀스를 다음 단계의 입력으로 사용하는 기법이다.

즉, 디코더가 각 단계에서 정답 토큰의 벡터 표현을 직접 사용하여 다음 출력을 생성하도록 하는 것이다. 정답 토큰의 벡터 표현을  $y$로 사용하여, 모델이 보다 정확하게 학습할 수 있게 하는 것이다.


#### Reranker

![8](https://github.com/user-attachments/assets/936d6500-a4ce-49ad-8163-52841dfbb4fd){: .responsive-img .align-center}


Reranker는 각 생성 단계에서 관련성이 높은 문장을 동적으로 선택하여 생성기의 정확도를 높이는 역할을 한다. 이 모듈의 목적은 생성기 단계  $t$ 에서 관심 있는 문장, 즉 산술 표현의 다음 수치 인수가 위치한 문장을 찾는 것이다.

**Reranker Space**

여기서 Reranker Space 라는 내용이 나오는데 이는 재배치해야 하는 객체들, 즉 질문과 검색된 문장의 표현으로 구성되는 공간이다. 여기서 Reranker 가 재배치를 하기 위해 두 가지 기법을 사용하는데 하나는 Dual Attention 이고, 다른 하나는 Mean-Pooling 이다.

**Dual Attention**

Dual Attention 은 질문 표현  $H_Q$ 와 각 문장 표현  $H_{D_i}^R$  간의 상호 작용을 강화하기 위해 사용되는 메커니즘이다. 듀얼 어텐션은 질문과 문장 간의 양방향 상호작용을 가능하게 하여, 질문이 문장에 영향을 미치고, 문장이 질문에 영향을 미치도록 한다. 이는 질문 표현 $H_Q$와 각 문장 표현 $H_{DR_i}$간의 상호작용을 통해 새로운 표현$\hat{H}_{Q_i}$와 $\hat{H}_{DR_i}$를 생성한다.


$$\hat{H}Q^i, \hat{H}{D_i}^R = \text{DualAttention}(H_Q, H_{D_i}^R)$$

그런데 Dual Attention 이 정확히 어떻게 동작하는지 모르겠어서 따로 찾아보았다.


> ### Dual Attention의 작동 방식
> 
> 1.  **입력 시퀀스**:
>     
>     -   질문 시퀀스 $H_Q$ : 질문을 나타내는 벡터 표현.
>     -   문장 시퀀스$H_{DR_i}$​​ : 검색된 문장의 벡터 표현.
>     
> 2.  **Attention 메커니즘**:
>     
>     -   Attention 메커니즘은 주어진 쿼리가 다른 시퀀스의 각 요소에 대해 중요도를 계산하여 각 요소의 가중치를 조정한다.
>     -   이를 통해 시퀀스 간의 관련성이 높아지고, 특정 부분에 더 집중할 수 있게 된다.
>     
> 3.  **Dual Attention의 단계**:
>     
>     -   **첫 번째 Attention**:
>         
>         -   질문 $H_Q$​를 쿼리로 사용하여 문장 $H_{DR_i}$의 각 요소에 대한 가중치를 계산한다.
>         -   이를 통해 질문이 문장의 어떤 부분에 더 집중해야 하는지를 결정한다.
>         
>     -   **두 번째 Attention**:
>         
>         -   문장 $H_{DR_i}$를 쿼리로 사용하여 질문 $H_Q$의 각 요소에 대한 가중치를 계산한다.
>         -   이를 통해 문장이 질문의 어떤 부분에 더 주목해야 하는지를 결정한다.
>         
> 4.  **결과**:
>     
>     -   두 시퀀스의 상호작용을 통해 얻어진 새로운 표현 $\hat{H}_{Q_i}$와 $\hat{H}_{DR_i}$는 각각 질문과 문장의 상호작용을 반영한 결과입니다.
>     -   이 결과는 질문과 문장 간의 관계를 보다 명확하게 파악할 수 있도록 하여, Reranker가 가장 관련성이 높은 문장을 선택하는 데 도움을 준다.


그냥 각 문장에 따로 어텐션을 취하는 것이었다. 😓


**Mean-Pooling**

듀얼 어텐션을 통해 각 문장과 상호작용한 후, Mean-pooling을 통해 각 문장과 질문의 표현을 단일 벡터로 집약한다. Mean-Pooling은 각 토큰 표현의 평균을 취하여 문장 전체에 대한 대표적인 표현을 얻는 방법이다.


$h_Q^i = \text{MeanPooling}(\hat{H}Q^i)$


$h{D_i}^R = \text{MeanPooling}(\hat{H}_{D_i}^R)$


이렇게 생성된 질문의 여러 문장 표현을 어텐션 메커니즘을 통해 결합하여 최종적인 **질문 표현**을 만든다. 이 결합은 문장 간의 중요도를 고려하여 질문의 전체적인 의미를 대표하는 벡터를 생성한다.


$$h_Q = \text{Attention}(Q = \hat{y}_t, K = [h_Q^1; h_Q^2; \cdots; h_Q^k], V = [h_Q^1; h_Q^2; \cdots; h_Q^k])$$

얘는 $h_Q^i$ 를 통합한 최종 질문을 의미하고, 이전에 Mean Pooling을 한 $h{D_i}^R$ 와 ㅊ


Reranker 공간은  h_Q, h_{D_1}^R, \ldots, h_{D_k}^R 로 구성되며, 이는 Reranker가 처리할 대상들입니다.

Reranker Query

재정렬에 사용되는 쿼리는 생성된 표현  Y_t 와 관련된 것뿐만 아니라 표현에서 추출된 토큰의 소스 문장과도 관련이 있습니다.

	•	소스 문장 결정: 생성된 토큰이 수치라면 해당 토큰의 소스 문장을 찾아내고, DSL에 있는 경우 토큰의 표현을 유지합니다. 이는 각 생성 단계에서 어떤 문장이 관련이 있는지를 추적하는 데 도움이 됩니다.


\text{source}(y_i) = \begin{cases}
y_i, & \text{if } y_i \in H_{DSL} \\
h_D, & \text{if } y_i \text{ comes from } D \in D_{QR}
\end{cases}


여기서  D_{QR} = \{Q\} \cup D^R 입니다. 이는 질문 및 검색된 문장들의 집합입니다.

	•	소스 문장 표현 생성: 이전 단계에서 계산된 소스 문장 표현에 현재 단계의 표현을 추가합니다. 이 과정은 매 단계마다 소스 문장에 대한 정보가 누적되어 활용될 수 있도록 합니다.


H_{src}^t = H_{src}^{t-1}; \text{source}(y_{t-1})


	•	쿼리 생성: 현재 단계의 모든 문장을 재정렬하기 위해 LSTM의 현재 출력을 사용하여 재정렬 쿼리 표현을 생성합니다. 이 쿼리는 현재 생성 단계에서 가장 관련성이 높은 문장을 찾는 데 사용됩니다.


Q_s = \text{Attention}(Q = \hat{y}t, K = H{src}^t, V = H_{src}^t)


Reranker Scorer

Reranker는 쿼리  Q_s 와 Reranker 공간 \{h_Q, h_{D_1}, \ldots, h_{D_k}\}을 사용하여 각 문장의 관련성을 계산합니다.

	•	관련성 점수 계산: 각 문장과 질문의 조합에 대해 관련성 점수를 계산합니다. 이 과정은 문장이 질문에 대해 얼마나 중요한지를 측정하여, 각 문장이 갖는 중요도를 평가합니다.


s_Q = \text{Linear}(\text{Tanh}(\text{Linear}([Q_s \| h_Q])))


s_{D_i}^R = \text{Linear}(\text{Tanh}(\text{Linear}([Q_s \| h_{D_i}^R]))), i \in \{1, \ldots, k\}


	•	최종 점수 계산: 재정렬 점수는 각 문장의 점수를 토큰으로 확장하여 모든 토큰의 최종 점수를 산출합니다. 이를 통해 문장 내의 각 토큰이 얼마나 중요한지 판단할 수 있습니다.


s_r = \text{Expand}(\text{Softmax}([s_Q, s_{D_1}^R, \ldots, s_{D_k}^R]))


DSL에 있는 토큰의 점수는 1.0으로 고정됩니다. 이는 DSL 토큰이 항상 선택 가능하다는 것을 의미합니다.

Reranker는 생성기와 상호작용하여 각 생성 단계에서 적절한 문장을 선택하도록 돕습니다. 이를 통해 수치 추론의 정확도를 높이고, 잘못된 문장 선택으로 인한 오류를 줄일 수 있습니다. 이 메커니즘은 동적 재정렬을 통해 생성기의 문장 선택 과정을 효과적으로 지원하여, 특히 숫자 추출과 같은 세부적인 작업에서 성능을 향상시킵니다.

[^1]: [DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs](https://aclanthology.org/N19-1246.pdf)

[^2]:A Numerical Reasoning Question Answering System with Fine-grained Retriever and the Ensemble of Multiple Generators for FINQA

<!--stackedit_data:
eyJoaXN0b3J5IjpbNjQ1NDIxMTYsMTM3NDc0OTM3NSwxMzI0Mz
k2MDA0LC01MTk4NjA3ODksMTc0MzQyNzM4MiwxMjY3NTA0NDk1
LDExMDE2ODMzMjEsLTIwNDk4MTk1NjUsMTQwNDIxOTQ3MSwtMT
I2OTA1NTQ4OSwxNTk0MTQ5NTQ5LC0xNjY1ODYwMzE3LC0xOTAz
NTU4MTcxLDE1OTgzNTQ5ODgsLTk0NzkwMTEyLC0xNjIzNTUxND
Q1LDc5Njc4NTU3OSwtNDE4OTgzNjI2LDgwMzQyNjMxMCw5NjI3
NjE5NzldfQ==
-->