---
title: CMU Advanced NLP 2024 (6) Generation Algorithms
author: Sohyun
layout: post
---

위 강의에서는 여러 생성 알고리즘(Generation Algorithms)과, 이와 관련된 여러 이론을 설명하고 있다.

교수는 먼저 하나의 모델 $M$을 가정하고 강의를 시작한다.

해당 모델은 70억 개의 매개변수로 이루어져있고, 가장 최신의 아키텍쳐로 사전 학습된 모델이며, 수 조개의 텍스트 토큰으로 사전 학습되었다. 또한, 여러 리더보드에서 최고의 성능을 자랑하는 매우 유명한 모델이라고 말한다.

하지만 모델 $M$을 자세히 살펴보면, 사실 이 모델은 조건부 확률 분포를 정의한다. 모델이 조건부 확률 분포를 정의한다는 것은, 모델이 특정 조건 $X$가 주어졌을 때 다른 변수 $Y$의 분포를 예측하거나 설명할 수 있다는 의미이다. 모델에 입력 $X$를 넣으면, 관심 있는 시퀀스에 대한 확률을 출력한다. 특히, $M$은 어휘의 모든 토큰에 대한 확률 분포를 제공하여 다음에 어떤 토큰을 출력할지 예측한다. 이러한 의미를 아래의 식이 내포한다.

$$P(Y | X) = \prod_{j=1}^{J} P(y_j | X, y_1, \ldots, y_{j-1})$$

•  **입력과 예측**: 입력 $X$와 지금까지 예측한 모든 것을 기반으로 다음 토큰 $y_j$의 확률을 제공한다.

•  **확률 계산**: 시퀀스 내 모든 확률을 곱하면, 입력 $X$에 대한 출력 $Y$의 확률을 계산할 수 있다.

즉, 이 고급 모델은 단순히 조건부 확률 분포에 불과하다. 그럼에도 불구하고, 이를 활용하여 번역, 요약, 추론 등 다양한 NLP 작업을 수행할 수 있다. 입력 X와 출력 Y의 정의를 바꾸는 것만으로도 다양한 작업에 적용할 수 있다. 아래는 그 예시이다.


![제목 없음](https://github.com/user-attachments/assets/f49d05b4-2125-4730-916c-e4b2280b2ea6){: .responsive-img .align-center}



모델이 단순한 확률 분포로 작동할 때의 좋은 점은 모델이 예측의 확신도(confidence)를 제공할 수 있다는 것이다. 예를 들어 "2 + 2 = ?"라는 입력에 대해 모델이 '4'에 높은 확률을 부여하면, 모델이 매우 확신하고 있음을 알 수 있다. 반면, "교수가 좋아하는 색깔은?" 같은 질문에 대해서는 분포가 평평하게 나타나 확신도가 낮음을 알 수 있다.


![2](https://github.com/user-attachments/assets/2b8033f2-0f0e-4a86-af23-65dfb49dea94){: .responsive-img .align-center}


그러나 이러한 확률 분포 모델은 잘못된 출력을 생성할 수도 있다. 모델은 잘못된 단어에도 0이 아닌 적은 확률을 할당하기 때문에 예측 시, 잘못되거나 이상한 출력을 생성할 가능성이 있다. 이러한 문제는 모델이 훈련된 데이터가 완벽하더라도 발생할 수 있다. 이러한 문제를 할루시네이션(Hallucination)이라고 한다.

이러한 문제를 해결할 방법으로 해당 강의에서는 **샘플링**을 소개한다.


## 샘플링(Sampling for LMs)

모델에서 좋은 출력을 얻기 위한 방법 중 하나가 바로 샘플링이다. 다양한 샘플링 기법들이 있으며, 각 방법은 모델의 확률 분포에서 토큰을 선택하는 방법에 따라 다르다.

첫 번째로 소개하는 것은 단순 샘플링(Ancestral Sampling)이다.

### 단순 샘플링(Ancestral Sampling)

단순 샘플링은 단순히 확률 분포에 따라 토큰을 무작위로 선택하는 방법이다. 확률이 높은 토큰일수록 고를 확률이 높기 때문에 당연히 선택될 확률도 높다. 각 시간 단계(time step)마다 토큰을 하나씩 샘플링하며, 모델 분포에 따라 샘플링하기 때문에 분포에 맞는 샘플, 즉, 많은 샘플을 선택하다 보면 모델 분포와 거의 일치하는 결과를 얻을 수 있다. 이로 인해, 확률이 낮은 토큰도 선택 가능성이 있으며, 다양한 결과를 얻을 수 있다. 하지만 이 샘플링은 긴 꼬리 분포 문제를 겪게 된다.

**긴 꼬리 분포 문제란?** 

긴 꼬리 분포는 높은 확률을 가진 토큰이 일부이고, 많은 토큰들이 낮은 확률을 가지지만, 이들이 모여서 전체 확률의 절반 가까이를 차지하는 모양의 분포를 의미한다. 

![3](https://github.com/user-attachments/assets/98fbf138-489d-4ae9-aa56-ff9ac794a723){: .responsive-img .align-center}

대충 이런 모양의 분포이다.

이러한 분포의 문제는 결과적으로, 샘플링할 때 이러한 낮은 확률의 토큰이 선택될 가능성이 높다는 것이다. 위의 그림에서 녹색 부분과 노란 부분은 각각 절반 정도의 비율을 차지하는데, 녹색 부분이 더 정답에 가까운 친구들임에도 단순 샘플링을 통해 샘플링을 진행할 경우, 50%의 확률로 노란 부분을 선택하게 된다는 것이다. 

이런 문제를 해결하기 위해 고안된 것 중 하나가  바로 Top-k 샘플링이다.


### Top-k 샘플링

이 방법은 상위 K개의 토큰, 즉 가장 확률이 높은 K개의 토큰만 선택하여 이들 중에서 샘플링하는 것이다. K의 경우 사용자가 지정할 수 있다. 예를 들어 K가 6일 경우, 상위 6개의 토큰 중에서 샘플링을 하는 것이다.

이 경우 위와 같은 긴 꼬리 분포를 띄는 상황에서 확률 질량의 대부분을 차지하는 토큰들만 샘플링하여 긴 꼬리의 영향을 줄일 수 있다. 하지만 때로는 상위 K개의 토큰만으로 충분하지 않을 수 있고, 만약 분포가 평평할 경우, 상위 K개의 토큰이 전체 확률의 대부분을 차지하지 않을 수 있다.

### Top-P(or Nucleus) 샘플링

이 방법은 샘플링할 집합을 뽑을 때, 갯수가 아닌 확률 질량의 총합을 기준으로 뽑는 방법이다. 여기서 p가 해당 확률을 나타내는 값이고, 만약 p 가 0.94 즉, 94%라면 가장 확률이 높은 토큰부터 시작해, 누적 확률이 94%에 도달할 때까지 집합에 토큰을 추가한 후, 해당 집합에서 샘플링을 진행하는 방법이다. 이 방법의 장점은 분포의 형태에 따라 동적으로 토큰 집합을 구성하여, 상위 K 샘플링보다 유연하게 작동한다는 것이다. 또한 정말 필요없는 토큰들을 확실히 배제할 수 있다. 하지만 상황에 따라 확률 질량의 누적 합이 P에 도달하기 전까지 많은 토큰을 포함해야 할 수 있다.


### 앱실론 $\epsilon$ 샘플링

앱실론 샘플링의 경우 최소 확률이 $\epsilon$ 이상인 토큰들만 샘플링하는 방법이다. 즉 만약 $\epsilon$이 0.05 일 경우, 해당 확률을 넘는 토큰들만 샘플링 대상에 포함하는 것이다. 이렇게 함으로써 확률이 매우 낮은 토큰을 배제하여 샘플링의 품질을 높일 수 있다. 하지만 반대로 낮은 확률의 토큰이 필요한 경우(즉 확률이 낮지만 정답일 경우), 이를 배제해버릴 수 있다.


샘플링에 있어 긴 꼬리 분포만이 고려되어야 할 점은 아니다.  **온도** 또한 주목하여야 한다. 확률 분포에서 온도는 샘플링 시 모델의 확률 분포를 조정하여 생성되는 텍스트의 다양성과 결정성을 제어하는데 사용되는 파라미터이다. 온도 파라미터를 분포를 평평하게 하거나 더 날카롭게 만들 수 있는데, 온도를 크게 할 경우(T>1) 분포가 평평해지고 반대로 온도를 작게 할 경우(T<1) 분포가 날카로워진다. 이야기 생성 모델과 같은 경우 분포를 넓게 하는 즉, 온도를 높이는 것이 좋을 것이고, 반대로 수학 문제를 푸는 것과 같은 경우에는 온도를 낮추는 것이 더 좋기 때문에 상황에 따라 잘 조절하여야 한다. 이러한 온도에 대한 처리는 Softmax 를 취하기 이전에 모델의 마지막 레이어에서 나온 출력, 즉 모델이 예측한 로짓에다가 처리를 하게 된다. 이 처리된 로짓에 Softmax를 취해서 최종 확률 분포를 구하게 된다. 이걸 식으로 표현하면 다음과 같다. $$z_i^′​=\frac{z_i}{T}$$

​​이런 온도를 적용하고 이전에 쓴 Top-k 나 Top-p 를 쓸 수 있지만, 보통은 온도만 적용하고 단순히 샘플링한다고 한다. 이러한 샘플링을 Temperture Sampling 이라고 한다.

이제부턴 조금 더 복잡한 샘플링 방법에 대해 알아보자.

### 대비 디코딩(Contrastive Decoding)

대비 디코딩은 디코딩 시 추가 정보를 활용하여 더 나은 출력을 생성하는 방법이다. 다른 분포나 다른 데이터를 활용할 수도 있지만, 여기서는 추가 모델을 활용한다. 여기서는 대규모 언어 모델과 소규모 언어 모델을 동시에 사용하여 출력을 생성하고, 두 모델 간의 차이를 활용해 출력을 개선한다.

작은 모델(gpt2 small 등)은 종종 반복적인 출력을 생성하거나 잘못된 출력을 제공할 수 있다. 큰 모델(gpt2 XL 등)은 더 많은 데이터로 훈련되어 이러한 문제를 덜 겪는다. 큰 모델이 높은 확률을 부여하지만 작은 모델이 낮은 확률을 부여하는 출력은, 큰 모델이 추가적인 지식을 통해 학습한 결과일 가능성이 높다.

대비 디코딩의 과정은 다음과 같다.

1. 먼저 두 모델(작은 모델과 큰 모델)이 동일한 입력에 대해 각각의 확률 분포를 생성한다.
2. 그 후 두 모델의 확률 값 차이를 계산한다.

$$Contrastive Score(x_i​)=\log P_l (x_i​) − \log P_s(x_i​)$$

3. 대비 점수가 높은 토큰을 선택하여 최종 출력을 생성한다. 큰 모델의 출력을 기본으로 하되, 작은 모델이 주는 추가적인 단서를 고려하여 조정한다. 

Contrastive decoding의 작동 방식은 다음과 같다.

![Screenshot 2024-08-01 at 7:13:07 PM](https://github.com/user-attachments/assets/b0e73a8a-8aa1-4b90-a28e-62ed3b23fee5){: .responsive-img .align-center}


-   **입력 예시**: "Barack Obama was born in Hawaii. He was born in L..."와 같은 입력이 주어졌을 때, 작은 모델은 종종 반복적인 출력을 생성하거나, 잘못된 사실을 출력할 수 있다.

-   **큰 모델의 출력 보정**: 큰 모델에서 높은 확률을 가진 출력을 유지하고, 작은 모델에서 높은 확률을 가진 잘못된 출력을 제거하여 더 정확한 출력을 얻는다.

-   **결과**: 예를 들어, 큰 모델은 "Barack Obama was born in 1961."이라는 정확한 출력을 제공할 수 있다.

이러한 대조적인 학습을 통해 큰 모델이 가진 장점을 활용해 출력을 더욱 정확하게 만들 수 있으며, 작은 모델이 자주 겪는 반복이나 오류를 줄일 수 있다.

강의에선 단순히 큰 모델의 지식을 활용하여 더 정확한 출력을 얻는다고 까지만 설명하는데, 이 부분이 잘 이해가 안되었다. 결국 큰 모델을 기반으로 하고 큰 모델이 더 정확한 결과를 쓴다고 가정을 했다면, 굳이 작은 모델을 쓰는 이유가 있을까? 단순히 큰 모델을 활용하면 끝나는 것이 아닐까? 실제로 대비 디코딩은 모델을 두 개 사용하기 때문에 이로인한 추가적인 비용과 복잡성을 피할 수 없다. 그럼에도 사용하는 이유는 다음과 같다고 한다.

> #### 1. 오류 탐지 및 보완
> 
> -   **오류 탐지**: 작은 모델과 큰 모델 간의 출력 차이를 비교함으로써 큰 모델이 실수할 가능성이 있는 부분을 식별할 수 있습니다. 큰 모델이 항상 옳지 않을 수 있으며, 작은 모델의 간단한 예측이 오히려 적합한 경우도 있습니다.
>     
> -   **보완 효과**: 대비 점수를 통해 큰 모델이 놓치는 작은 모델의 간단한 패턴을 발견할 수 있으며, 이를 통해 더 정교한 출력을 생성할 수 있습니다.
>     
> 
> #### 2. 비용 효율성
> 
> -   **부분적 사용**: 작은 모델을 먼저 사용하여 많은 후보를 생성하고, 이 후보 중 일부에만 큰 모델을 적용함으로써 전체적인 비용을 줄일 수 있습니다. 이는 큰 모델을 모든 후보에 적용하는 것보다 효율적일 수 있습니다.
>     
> -   **스마트한 자원 사용**: 큰 모델을 항상 사용하는 것이 아니라 필요한 경우에만 사용하는 전략을 통해 계산 비용을 최적화할 수 있습니다.
>     
> 
> #### 3. 예비 필터링 및 속도 향상
> 
> -   **빠른 초기 처리**: 작은 모델을 사용하여 빠르게 초기 예측을 수행하고, 중요한 예측만 큰 모델로 자세히 분석함으로써 전체적인 처리 시간을 줄일 수 있습니다.
>     
> -   **실시간 시스템에서의 사용**: 작은 모델로 실시간 응답을 처리하고, 큰 모델로 배치 후처리하는 구조를 사용할 수 있습니다.
>     
> 
> #### 4. 모델 결합의 추가 장점
> 
> -   **다양성 유지**: 작은 모델과 큰 모델의 결합은 출력에서 다양한 관점을 반영할 수 있게 하며, 이는 텍스트 생성에서 더 창의적이고 인간적인 출력을 만들어낼 수 있습니다.
>     
> -   **모델 신뢰도 개선**: 두 모델 간의 대비를 통해 얻는 정보는 모델의 신뢰도를 높이는 데 기여할 수 있습니다. 대비 디코딩은 모델의 불확실성을 줄이고 더 나은 결과를 제공할 수 있습니다.


그런데 이럼에도 이해가 되지 않는 것이 대비 점수가 클 경우 모델이 이를 어떻게 판단하는지가 잘 감이 오지 않았다. 단순히 큰 모델이 맞다고 판단할 것인가? 그렇다면 이전에 말한 것처럼 큰 모델만 사용하는 것이 훨씬 나은 것이 아닐까? 이에 대한 처리 방법은 다양하게 있다고 하는데


> #### 1. **가중 평균 접근**
> 
> -   **가중 평균 계산**: 두 모델의 출력을 조합하여 새로운 확률을 계산합니다. 큰 모델의 출력을 더 많이 반영하거나, 작은 모델이 중요한 역할을 할 경우 더 평등하게 반영합니다.
>     
>    $$P_{\text{combined}}(x_i) =
> \alpha \cdot P_{\text{large}}(x_i) + (1 - \alpha) \cdot
> P_{\text{small}}(x_i)$$
>     
>     여기서 $\alpha$는 가중치를 조절하는 파라미터로, 일반적으로 0.5에서 1 사이의 값을 가질 수 있습니다.
>     
> -   **유연성 제공**: 이 접근법은 두 모델 간의 상호작용을 유연하게 조정할 수 있어, 상황에 따라 큰 모델의 영향력을 높이거나 작은 모델의 의견을 더 반영할 수 있습니다.
>     
> 
> #### 2. **신뢰도 기반 선택**
> 
> -   **신뢰도 평가**: 각 모델의 신뢰도를 특정 상황에 맞게 설정합니다. 예를 들어, 특정 도메인에서는 큰 모델이 더 신뢰할 만한 경우가 많을 수 있지만, 다른 도메인에서는 작은 모델의 간단한 추론이 더 적합할 수 있습니다.
>     
> -   **도메인 지식 활용**: 신뢰도 판단 시 도메인 지식이나 과거 경험을 활용하여 특정 상황에 따라 어느 모델의 출력을 더 신뢰할지를 결정합니다.
>     
> 
> #### 3. **후처리 단계 추가**
> 
> -   **후처리 검증**: 두 모델 간의 차이를 감지한 후, 특정 규칙이나 외부 지식 기반을 사용하여 최종 출력을 검증하고 조정합니다. 이는 두 모델의 장점을 최대한 활용하여 최종 출력을 개선하는 데 도움이 됩니다.
>     
> -   **피드백 루프**: 모델이 잘못된 예측을 할 경우, 해당 예측을 학습 데이터에 반영하여 모델의 성능을 점진적으로 개선할 수 있는 피드백 루프를 구성합니다.


즉, 두 모델 간의 대비 점수가 클 때는, 단순히 큰 모델의 예측만을 신뢰하기보다는 다양한 방법을 통해 최종 출력을 결정하는 것이 중요하다고 한다. 이는 모델의 예측을 더욱 신뢰성 있게 만들고, 다양한 시나리오에서 더 높은 품질의 출력을 제공할 수 있도록 한다.



<!--stackedit_data:
eyJoaXN0b3J5IjpbLTY5OTQwMjg5MiwtMTA5MzMyNTMxOCwxMD
YxMTcyNTM0LDE2NDkxNDIxODAsMjAxNjQ5MzAsMTM5MzgyNDE2
LC02MzA2MTA2NTksLTEyODg3NDQzMTUsODc4MTY0NjA5LDY2Mz
I5MDM4MywtMTA5OTYzODQ1NywtMjI1MTM2NDIwLDc2NzM3NzM5
NywtMTkzOTQ1OTE1OSwtMTMwMzc2NTc5MywtOTAxODY0MzU1LD
E3OTQwNTgyMTQsLTEwOTY3OTI2MDgsLTE5NTgwNjUyNSwzNDUw
MjY4NTldfQ==
-->